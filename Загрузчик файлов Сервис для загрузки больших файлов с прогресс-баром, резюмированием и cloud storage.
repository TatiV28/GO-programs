FileName     string         `json:"file_name" gorm:"not null"`
	OriginalName string         `json:"original_name" gorm:"not null"`
	ContentType  string         `json:"content_type"`
	FileSize     int64          `json:"file_size" gorm:"not null"`
	ChunkSize    int64          `json:"chunk_size" gorm:"default:1048576"` // 1MB по умолчанию
	TotalChunks  int            `json:"total_chunks" gorm:"not null"`
	
	Status       string         `json:"status" gorm:"default:pending"` // pending, uploading, completed, failed, cancelled
	Progress     float64        `json:"progress" gorm:"default:0"`
	UploadedSize int64          `json:"uploaded_size" gorm:"default:0"`
	
	StorageProvider string        `json:"storage_provider" gorm:"default:local"`
	StoragePath     string        `json:"storage_path"`
	PublicURL       string        `json:"public_url"`
	
	UserID       *string        `json:"user_id,omitempty"`
	ExpiresAt    *time.Time     `json:"expires_at,omitempty"`
	
	Chunks       []Chunk        `json:"chunks,omitempty" gorm:"foreignKey:UploadID"`
}

type Chunk struct {
	ID          uint           `json:"id" gorm:"primarykey"`
	CreatedAt   time.Time      `json:"created_at"`
	UpdatedAt   time.Time      `json:"updated_at"`
	DeletedAt   gorm.DeletedAt `json:"-" gorm:"index"`
	
	UploadID    string         `json:"upload_id" gorm:"not null;type:uuid"`
	ChunkIndex  int            `json:"chunk_index" gorm:"not null"`
	ChunkSize   int64          `json:"chunk_size" gorm:"not null"`
	Checksum    string         `json:"checksum"` // MD5 или SHA256
	StoragePath string         `json:"storage_path"`
	Status      string         `json:"status" gorm:"default:pending"` // pending, uploaded, verified, failed
	
	Upload      FileUpload     `json:"-" gorm:"foreignKey:UploadID"`
}

type UploadStartRequest struct {
	FileName    string `json:"file_name" binding:"required"`
	FileSize    int64  `json:"file_size" binding:"required,min=1"`
	ContentType string `json:"content_type"`
	ChunkSize   int64  `json:"chunk_size,omitempty"`
	UserID      string `json:"user_id,omitempty"`
}

type UploadChunkRequest struct {
	UploadID   string `json:"upload_id" binding:"required"`
	ChunkIndex int    `json:"chunk_index" binding:"required,min=0"`
	Checksum   string `json:"checksum,omitempty"`
}

type UploadCompleteRequest struct {
	UploadID string `json:"upload_id" binding:"required"`
	Checksum string `json:"final_checksum,omitempty"`
}

// storage.go
package main

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
)

type StorageProvider interface {
	SaveChunk(uploadID string, chunkIndex int, data io.Reader, size int64) (string, error)
	CombineChunks(uploadID string, chunks []Chunk, finalPath string) error
	DeleteFile(path string) error
	GetFileURL(path string) (string, error)
	GetFile(path string) (io.ReadCloser, error)
}

// LocalStorage - локальное хранилище
type LocalStorage struct {
	basePath string
}

func NewLocalStorage() (*LocalStorage, error) {
	basePath := os.Getenv("UPLOAD_PATH")
	if basePath == "" {
		basePath = "./uploads"
	}
	
	// Создаем директории
	if err := os.MkdirAll(basePath, 0755); err != nil {
		return nil, err
	}
	if err := os.MkdirAll(filepath.Join(basePath, "chunks"), 0755); err != nil {
		return nil, err
	}
	if err := os.MkdirAll(filepath.Join(basePath, "files"), 0755); err != nil {
		return nil, err
	}
	
	return &LocalStorage{basePath: basePath}, nil
}

func (ls *LocalStorage) SaveChunk(uploadID string, chunkIndex int, data io.Reader, size int64) (string, error) {
	chunkPath := filepath.Join(ls.basePath, "chunks", fmt.Sprintf("%s_%d.chunk", uploadID, chunkIndex))
	
	file, err := os.Create(chunkPath)
	if err != nil {
		return "", err
	}
	defer file.Close()
	
	_, err = io.Copy(file, data)
	return chunkPath, err
}

func (ls *LocalStorage) CombineChunks(uploadID string, chunks []Chunk, finalPath string) error {
	finalFilePath := filepath.Join(ls.basePath, "files", finalPath)
	
	finalFile, err := os.Create(finalFilePath)
	if err != nil {
		return err
	}
	defer finalFile.Close()
	
	// Сортируем чанки по индексу
	for i := 0; i < len(chunks); i++ {
		for _, chunk := range chunks {
			if chunk.ChunkIndex == i {
				chunkFile, err := os.Open(chunk.StoragePath)
				if err != nil {
					return err
				}
				
				_, err = io.Copy(finalFile, chunkFile)
				chunkFile.Close()
				
				if err != nil {
					return err
				}
				
				// Удаляем чанк после объединения
				os.Remove(chunk.StoragePath)
				break
			}
		}
	}
	
	return nil
}

func (ls *LocalStorage) DeleteFile(path string) error {
	return os.Remove(filepath.Join(ls.basePath, "files", path))
}

func (ls *LocalStorage) GetFileURL(path string) (string, error) {
	// Для локального хранилища возвращаем относительный URL
	return fmt.Sprintf("/files/%s", path), nil
}

func (ls *LocalStorage) GetFile(path string) (io.ReadCloser, error) {
	return os.Open(filepath.Join(ls.basePath, "files", path))
}

// S3Storage - Amazon S3 хранилище
type S3Storage struct {
	bucket string
	region string
}

func NewS3Storage() (*S3Storage, error) {
	bucket := os.Getenv("S3_BUCKET")
	region := os.Getenv("S3_REGION")
	
	if bucket == "" || region == "" {
		return nil, fmt.Errorf("S3_BUCKET и S3_REGION должны быть установлены")
	}
	
	return &S3Storage{
		bucket: bucket,
		region: region,
	}, nil
}

func (s3 *S3Storage) SaveChunk(uploadID string, chunkIndex int, data io.Reader, size int64) (string, error) {
	// Реализация сохранения чанка в S3
	key := fmt.Sprintf("chunks/%s_%d.chunk", uploadID, chunkIndex)
	// Здесь должна быть логика загрузки в S3
	return key, nil
}

func (s3 *S3Storage) CombineChunks(uploadID string, chunks []Chunk, finalPath string) error {
	// Реализация объединения чанков в S3 с помощью multipart upload
	return nil
}

func (s3 *S3Storage) DeleteFile(path string) error {
	// Реализация удаления файла из S3
	return nil
}

func (s3 *S3Storage) GetFileURL(path string) (string, error) {
	// Возвращаем presigned URL или публичный URL
	return fmt.Sprintf("https://%s.s3.%s.amazonaws.com/%s", s3.bucket, s3.region, path), nil
}

func (s3 *S3Storage) GetFile(path string) (io.ReadCloser, error) {
	// Реализация получения файла из S3
	return nil, nil
}

// GCS и Azure Storage аналогично...
type GCSStorage struct{}
type AzureStorage struct{}

func NewGCSStorage() (*GCSStorage, error) { return &GCSStorage{}, nil }
func NewAzureStorage() (*AzureStorage, error) { return &AzureStorage{}, nil }

func (gcs *GCSStorage) SaveChunk(uploadID string, chunkIndex int, data io.Reader, size int64) (string, error) { return "", nil }
func (gcs *GCSStorage) CombineChunks(uploadID string, chunks []Chunk, finalPath string) error { return nil }
func (gcs *GCSStorage) DeleteFile(path string) error { return nil }
func (gcs *GCSStorage) GetFileURL(path string) (string, error) { return "", nil }
func (gcs *GCSStorage) GetFile(path string) (io.ReadCloser, error) { return nil, nil }

func (az *AzureStorage) SaveChunk(uploadID string, chunkIndex int, data io.Reader, size int64) (string, error) { return "", nil }
func (az *AzureStorage) CombineChunks(uploadID string, chunks []Chunk, finalPath string) error { return nil }
func (az *AzureStorage) DeleteFile(path string) error { return nil }
func (az *AzureStorage) GetFileURL(path string) (string, error) { return "", nil }
func (az *AzureStorage) GetFile(path string) (io.ReadCloser, error) { return nil, nil }

// service.go
package main

import (
	"crypto/md5"
	"fmt"
	"io"
	"math"
	"net/http"
	"strconv"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/google/uuid"
	"gorm.io/gorm"
)

type UploadService struct {
	db      *gorm.DB
	storage StorageProvider
}

func NewUploadService(db *gorm.DB, storage StorageProvider) *UploadService {
	return &UploadService{
		db:      db,
		storage: storage,
	}
}

func (s *UploadService) StartUpload(c *gin.Context) {
	var req UploadStartRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	// Устанавливаем размер чанка по умолчанию
	if req.ChunkSize <= 0 {
		req.ChunkSize = 1048576 // 1MB
	}

	// Вычисляем количество чанков
	totalChunks := int(math.Ceil(float64(req.FileSize) / float64(req.ChunkSize)))

	upload := FileUpload{
		ID:           uuid.New().String(),
		FileName:     fmt.Sprintf("%d_%s", time.Now().Unix(), req.FileName),
		OriginalName: req.FileName,
		ContentType:  req.ContentType,
		FileSize:     req.FileSize,
		ChunkSize:    req.ChunkSize,
		TotalChunks:  totalChunks,
		Status:       "pending",
		StorageProvider: "local", // или из конфигурации
	}

	if req.UserID != "" {
		upload.UserID = &req.UserID
	}

	if err := s.db.Create(&upload).Error; err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка создания загрузки"})
		return
	}

	c.JSON(http.StatusCreated, gin.H{
		"upload_id":    upload.ID,
		"chunk_size":   upload.ChunkSize,
		"total_chunks": upload.TotalChunks,
		"message":      "Загрузка инициализирована",
	})
}

func (s *UploadService) UploadChunk(c *gin.Context) {
	uploadID := c.GetHeader("X-Upload-ID")
	chunkIndexStr := c.GetHeader("X-Chunk-Index")
	checksum := c.GetHeader("X-Chunk-Checksum")

	if uploadID == "" || chunkIndexStr == "" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Отсутствуют обязательные заголовки"})
		return
	}

	chunkIndex, err := strconv.Atoi(chunkIndexStr)
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Неверный индекс чанка"})
		return
	}

	// Проверяем существование загрузки
	var upload FileUpload
	if err := s.db.First(&upload, "id = ?", uploadID).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}

	if upload.Status == "completed" || upload.Status == "cancelled" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Загрузка уже завершена или отменена"})
		return
	}

	// Проверяем, не загружен ли уже этот чанк
	var existingChunk Chunk
	if err := s.db.Where("upload_id = ? AND chunk_index = ?", uploadID, chunkIndex).First(&existingChunk).Error; err == nil {
		c.JSON(http.StatusConflict, gin.H{"error": "Чанк уже загружен"})
		return
	}

	// Получаем данные чанка
	file, header, err := c.Request.FormFile("chunk")
	if err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Ошибка получения файла"})
		return
	}
	defer file.Close()

	// Проверяем размер чанка
	if header.Size > upload.ChunkSize {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Размер чанка превышает допустимый"})
		return
	}

	// Вычисляем контрольную сумму если требуется
	var calculatedChecksum string
	if checksum != "" {
		hash := md5.New()
		if _, err := io.Copy(hash, file); err != nil {
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка вычисления контрольной суммы"})
			return
		}
		calculatedChecksum = fmt.Sprintf("%x", hash.Sum(nil))
		
		if calculatedChecksum != checksum {
			c.JSON(http.StatusBadRequest, gin.H{"error": "Контрольная сумма не совпадает"})
			return
		}
		
		// Сбрасываем указатель файла
		file.Seek(0, 0)
	}

	// Сохраняем чанк в хранилище
	storagePath, err := s.storage.SaveChunk(uploadID, chunkIndex, file, header.Size)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сохранения чанка"})
		return
	}

	// Сохраняем информацию о чанке в БД
	chunk := Chunk{
		UploadID:    uploadID,
		ChunkIndex:  chunkIndex,
		ChunkSize:   header.Size,
		Checksum:    calculatedChecksum,
		StoragePath: storagePath,
		Status:      "uploaded",
	}

	if err := s.db.Create(&chunk).Error; err != nil {
		// Удаляем чанк из хранилища в случае ошибки БД
		s.storage.DeleteFile(storagePath)
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка сохранения информации о чанке"})
		return
	}

	// Обновляем прогресс загрузки
	s.updateUploadProgress(&upload)

	c.JSON(http.StatusOK, gin.H{
		"message":     "Чанк загружен успешно",
		"chunk_index": chunkIndex,
		"progress":    s.calculateProgress(uploadID),
	})
}

func (s *UploadService) CompleteUpload(c *gin.Context) {
	var req UploadCompleteRequest
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	// Получаем информацию о загрузке
	var upload FileUpload
	if err := s.db.Preload("Chunks").First(&upload, "id = ?", req.UploadID).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}

	// Проверяем, что все чанки загружены
	if len(upload.Chunks) != upload.TotalChunks {
		c.JSON(http.StatusBadRequest, gin.H{
			"error": "Не все чанки загружены",
			"uploaded": len(upload.Chunks),
			"total": upload.TotalChunks,
		})
		return
	}

	// Обновляем статус на "completing"
	upload.Status = "completing"
	s.db.Save(&upload)

	// Объединяем чанки в финальный файл
	if err := s.storage.CombineChunks(req.UploadID, upload.Chunks, upload.FileName); err != nil {
		upload.Status = "failed"
		s.db.Save(&upload)
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка объединения файла"})
		return
	}

	// Получаем URL файла
	fileURL, err := s.storage.GetFileURL(upload.FileName)
	if err != nil {
		upload.Status = "failed"
		s.db.Save(&upload)
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка получения URL файла"})
		return
	}

	// Обновляем информацию о загрузке
	upload.Status = "completed"
	upload.Progress = 100.0
	upload.UploadedSize = upload.FileSize
	upload.StoragePath = upload.FileName
	upload.PublicURL = fileURL
	
	if err := s.db.Save(&upload).Error; err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка обновления статуса"})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"message":    "Файл успешно загружен",
		"upload_id":  upload.ID,
		"file_url":   fileURL,
		"file_size":  upload.FileSize,
		"status":     upload.Status,
	})
}

func (s *UploadService) CancelUpload(c *gin.Context) {
	var req struct {
		UploadID string `json:"upload_id" binding:"required"`
	}
	
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	var upload FileUpload
	if err := s.db.Preload("Chunks").First(&upload, "id = ?", req.UploadID).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}

	// Удаляем чанки из хранилища
	for _, chunk := range upload.Chunks {
		s.storage.DeleteFile(chunk.StoragePath)
	}

	// Удаляем чанки из БД
	s.db.Where("upload_id = ?", req.UploadID).Delete(&Chunk{})

	// Обновляем статус загрузки
	upload.Status = "cancelled"
	s.db.Save(&upload)

	c.JSON(http.StatusOK, gin.H{"message": "Загрузка отменена"})
}

func (s *UploadService) GetUploads(c *gin.Context) {
	var uploads []FileUpload
	
	page, _ := strconv.Atoi(c.DefaultQuery("page", "1"))
	limit, _ := strconv.Atoi(c.DefaultQuery("limit", "10"))
	status := c.Query("status")
	userID := c.Query("user_id")
	
	offset := (page - 1) * limit
	
	query := s.db.Offset(offset).Limit(limit).Order("created_at DESC")
	
	if status != "" {
		query = query.Where("status = ?", status)
	}
	if userID != "" {
		query = query.Where("user_id = ?", userID)
	}
	
	result := query.Find(&uploads)
	if result.Error != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": result.Error.Error()})
		return
	}
	
	var total int64
	countQuery := s.db.Model(&FileUpload{})
	if status != "" {
		countQuery = countQuery.Where("status = ?", status)
	}
	if userID != "" {
		countQuery = countQuery.Where("user_id = ?", userID)
	}
	countQuery.Count(&total)
	
	c.JSON(http.StatusOK, gin.H{
		"uploads": uploads,
		"pagination": gin.H{
			"page":  page,
			"limit": limit,
			"total": total,
		},
	})
}

func (s *UploadService) GetUpload(c *gin.Context) {
	id := c.Param("id")
	var upload FileUpload
	
	result := s.db.Preload("Chunks").First(&upload, "id = ?", id)
	if result.Error != nil {
		if result.Error == gorm.ErrRecordNotFound {
			c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
			return
		}
		c.JSON(http.StatusInternalServerError, gin.H{"error": result.Error.Error()})
		return
	}
	
	c.JSON(http.StatusOK, upload)
}

func (s *UploadService) GetProgress(c *gin.Context) {
	id := c.Param("id")
	progress := s.calculateProgress(id)
	
	var upload FileUpload
	if err := s.db.First(&upload, "id = ?", id).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}
	
	c.JSON(http.StatusOK, gin.H{
		"upload_id": id,
		"progress":  progress,
		"status":    upload.Status,
		"uploaded_size": upload.UploadedSize,
		"total_size": upload.FileSize,
	})
}

func (s *UploadService) DeleteUpload(c *gin.Context) {
	id := c.Param("id")
	
	var upload FileUpload
	if err := s.db.Preload("Chunks").First(&upload, "id = ?", id).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}

	// Удаляем файл из хранилища
	if upload.StoragePath != "" {
		s.storage.DeleteFile(upload.StoragePath)
	}

	// Удаляем чанки из хранилища
	for _, chunk := range upload.Chunks {
		s.storage.DeleteFile(chunk.StoragePath)
	}

	// Удаляем из БД
	s.db.Where("upload_id = ?", id).Delete(&Chunk{})
	s.db.Delete(&upload)

	c.JSON(http.StatusOK, gin.H{"message": "Загрузка удалена"})
}

func (s *UploadService) DownloadFile(c *gin.Context) {
	id := c.Param("id")
	
	var upload FileUpload
	if err := s.db.First(&upload, "id = ?", id).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Файл не найден"})
		return
	}

	if upload.Status != "completed" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Файл еще не загружен"})
		return
	}

	file, err := s.storage.GetFile(upload.StoragePath)
	if err != nil {
		c.JSON(http.StatusInternalServerError, gin.H{"error": "Ошибка получения файла"})
		return
	}
	defer file.Close()

	c.Header("Content-Disposition", fmt.Sprintf("attachment; filename=\"%s\"", upload.OriginalName))
	c.Header("Content-Type", upload.ContentType)
	c.Header("Content-Length", strconv.FormatInt(upload.FileSize, 10))

	io.Copy(c.Writer, file)
}

func (s *UploadService) GetFileInfo(c *gin.Context) {
	id := c.Param("id")
	
	var upload FileUpload
	if err := s.db.First(&upload, "id = ?", id).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Файл не найден"})
		return
	}

	c.JSON(http.StatusOK, gin.H{
		"id":            upload.ID,
		"file_name":     upload.OriginalName,
		"content_type":  upload.ContentType,
		"file_size":     upload.FileSize,
		"status":        upload.Status,
		"created_at":    upload.CreatedAt,
		"public_url":    upload.PublicURL,
	})
}

func (s *UploadService) ResumeUpload(c *gin.Context) {
	var req struct {
		UploadID string `json:"upload_id" binding:"required"`
	}
	
	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
		return
	}

	var upload FileUpload
	if err := s.db.Preload("Chunks").First(&upload, "id = ?", req.UploadID).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}

	if upload.Status == "completed" {
		c.JSON(http.StatusBadRequest, gin.H{"error": "Загрузка уже завершена"})
		return
	}

	// Определяем какие чанки уже загружены
	uploadedChunks := make(map[int]bool)
	for _, chunk := range upload.Chunks {
		uploadedChunks[chunk.ChunkIndex] = true
	}

	missingChunks := make([]int, 0)
	for i := 0; i < upload.TotalChunks; i++ {
		if !uploadedChunks[i] {
			missingChunks = append(missingChunks, i)
		}
	}

	c.JSON(http.StatusOK, gin.H{
		"upload_id":      upload.ID,
		"total_chunks":   upload.TotalChunks,
		"progress":       s.calculateProgress(req.UploadID),
		"missing_chunks": missingChunks,
		"status":         upload.Status,
	})
}

func (s *UploadService) GetUploadStatus(c *gin.Context) {
	id := c.Param("id")
	
	var upload FileUpload
	if err := s.db.First(&upload, "id = ?", id).Error; err != nil {
		c.JSON(http.StatusNotFound, gin.H{"error": "Загрузка не найдена"})
		return
	}

	var uploadedChunks int64
	s.db.Model(&Chunk{}).Where("upload_id = ? AND status = ?", id, "uploaded").Count(&uploadedChunks)

	c.JSON(http.StatusOK, gin.H{
		"upload_id":       upload.ID,
		"status":          upload.Status,
		"progress":        s.calculateProgress(id),
		"uploaded_chunks": uploadedChunks,
		"total_chunks":    upload.TotalChunks,
		"file_size":       upload.FileSize,
		"uploaded_size":   upload.UploadedSize,
	})
}

// Вспомогательные методы
func (s *UploadService) updateUploadProgress(upload *FileUpload) {
	var uploadedSize int64
	s.db.Model(&Chunk{}).Where("upload_id = ? AND status = ?", upload.ID, "uploaded").Select("COALESCE(SUM(chunk_size), 0)").Scan(&uploadedSize)
	
	progress := float64(uploadedSize) / float64(upload.FileSize) * 100
	
	upload.UploadedSize = uploadedSize
	upload.Progress = progress
	
	if progress > 0 && upload.Status == "pending" {
		upload.Status = "uploading"
	}
	
	s.db.Save(upload)
}

func (s *UploadService) calculateProgress(uploadID string) float64 {
	var upload FileUpload
	if err := s.db.First(&upload, "id = ?", uploadID).Error; err != nil {
		return 0
	}
	
	var uploadedSize int64
	s.db.Model(&Chunk{}).Where("upload_id = ? AND status = ?", uploadID, "uploaded").Select("COALESCE(SUM(chunk_size), 0)").Scan(&uploadedSize)
	
	if upload.FileSize == 0 {
		return 0
	}
	
	return float64(uploadedSize) / float// File Upload Service with Progress, Resume & Cloud Storage
// main.go
package main

import (
	"log"
	"os"

	"github.com/gin-gonic/gin"
	"gorm.io/driver/postgres"
	"gorm.io/gorm"
)

func main() {
	// Подключение к базе данных
	db, err := initDB()
	if err != nil {
		log.Fatal("Ошибка подключения к базе данных:", err)
	}

	// Автоматическая миграция
	db.AutoMigrate(&FileUpload{}, &Chunk{})

	// Инициализация сервисов
	storageProvider, err := initStorageProvider()
	if err != nil {
		log.Fatal("Ошибка инициализации хранилища:", err)
	}

	uploadService := NewUploadService(db, storageProvider)
	
	// Настройка роутера
	r := gin.Default()
	r.Use(corsMiddleware())

	// Статические файлы для веб-интерфейса
	r.Static("/static", "./web/static")
	r.LoadHTMLGlob("web/templates/*")

	// Веб-интерфейс
	r.GET("/", func(c *gin.Context) {
		c.HTML(200, "upload.html", nil)
	})

	// API маршруты
	api := r.Group("/api")
	{
		// Загрузка файлов
		api.POST("/upload/start", uploadService.StartUpload)
		api.POST("/upload/chunk", uploadService.UploadChunk)
		api.POST("/upload/complete", uploadService.CompleteUpload)
		api.POST("/upload/cancel", uploadService.CancelUpload)
		
		// Управление загрузками
		api.GET("/uploads", uploadService.GetUploads)
		api.GET("/uploads/:id", uploadService.GetUpload)
		api.GET("/uploads/:id/progress", uploadService.GetProgress)
		api.DELETE("/uploads/:id", uploadService.DeleteUpload)
		
		// Скачивание файлов
		api.GET("/files/:id/download", uploadService.DownloadFile)
		api.GET("/files/:id/info", uploadService.GetFileInfo)
		
		// Resumable upload
		api.POST("/upload/resume", uploadService.ResumeUpload)
		api.GET("/upload/:id/status", uploadService.GetUploadStatus)
	}

	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}

	log.Printf("File Upload Service запущен на порту %s", port)
	r.Run(":" + port)
}

func initDB() (*gorm.DB, error) {
	dsn := os.Getenv("DATABASE_URL")
	if dsn == "" {
		dsn = "host=localhost user=postgres password=postgres dbname=fileuploaddb port=5432 sslmode=disable"
	}
	
	return gorm.Open(postgres.Open(dsn), &gorm.Config{})
}

func initStorageProvider() (StorageProvider, error) {
	storageType := os.Getenv("STORAGE_TYPE")
	switch storageType {
	case "s3":
		return NewS3Storage()
	case "gcs":
		return NewGCSStorage()
	case "azure":
		return NewAzureStorage()
	default:
		return NewLocalStorage()
	}
}

func corsMiddleware() gin.HandlerFunc {
	return func(c *gin.Context) {
		c.Header("Access-Control-Allow-Origin", "*")
		c.Header("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS")
		c.Header("Access-Control-Allow-Headers", "Origin, Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization, X-Upload-ID, X-Chunk-Index")

		if c.Request.Method == "OPTIONS" {
			c.AbortWithStatus(204)
			return
		}

		c.Next()
	}
}

// models.go
package main

import (
	"time"
	"gorm.io/gorm"
)

type FileUpload struct {
	ID           string         `json:"id" gorm:"primarykey;type:uuid;default:gen_random_uuid()"`
	CreatedAt    time.Time      `json:"created_at"`
	UpdatedAt    time.Time      `json:"updated_at"`
	DeletedAt    gorm.DeletedAt `json:"-" gorm:"index"`
	
	FileName     string         `json:"file_name" gorm:"not null"`
	OriginalName string
